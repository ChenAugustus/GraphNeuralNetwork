# GraphNeuralNetwork
图数据是我们常见的一种数据结构，与表数据、图片数据不同的是，图结构是一种非欧几里得空间上的数据形式，是不能直接利用深度学习算法来解决的。所以研究基于图数据的神经网络，我们称之为图神经网络。首先我们还是先来看看图数据的一些基本性质和特点，再分析一下图神经网络是如何适用于图数据结构特点的。


图数据是一种网络结构，可以分为很多种比如有向/无向图、带环/不带环图、同构/异构图、静态/动态图等，但都涉及到一些核心的特征，比如节点、关系、属性以及子图等概念。下图左边是一个抽象的图数据模型，右边是一个具体的实例，图神经网络的应用对象就是这种结构。

<div align=center><img width="400" height="300" src="https://github.com/xchadesi/st_graph_book/blob/master/docs/images/69.PNG"/>
  <img width="400" height="300" src="https://github.com/xchadesi/st_graph_book/blob/master/docs/images/70.PNG"/></div>

## 1 核心原理

图数据结构中包含的特征主要有两类：一类是图数据的结构特征，也就是网络节点之间的关系，包括节点和节点之间、节点和边之间、节点/边和全图之间等几种关系；一类是图数据的属性特征，包括节点的属性、边的属性、全图的属性等。为了研究一个全图，或者一个节点、一条边，我们需要学习、提取它们的这些特征。通过类比卷积神经网络学习和提取空间特征的方法，通过提供类似卷积的操作来学习图数据的结构化特征。这种类似卷积的操作，主要通过两种方式实现：其一是利用图谱分析理论，在图傅里叶转换的基础上定义卷积操作；其二是通过某些条件确定中心节点的接受域，来处理不同数目的邻节点特征，以此学习图属性、节点属性、边属性之间的相互作用，这些相互作用包括：
- 节点和全局属性之间的相互作用；
- 两个节点之间的相互作用；
- 边和发出节点、接受节点之间的相互作用；
- 边和全局属性之间的相互作用；<br>

<div align=center><img width="400" height="300" src="https://github.com/xchadesi/st_graph_book/blob/master/docs/images/68.PNG"/></div>

所谓“作用”在数学上具体可以表示为带有一组线性或非线性参数的函数，参数的大小决定了其作用和影响，这里的函数可以按照作用的方式分为“传播函数”、“更新函数”、“输出转换函数”等，而这些函数其实就是我们所设计的深度学习网络，对于具体问题的图网络设计就是要根据具体需求设计不同的网络网络形式（函数表达式）。

## 2 三个框架

关于具体的图网络结构，涉及到一些通用的模型框架，包括信息传递框架（MPNNs）、捕获长程依赖框架（NLNN）、通用图建模框架（GN）等，这些框架都各有其特色，但GN算是统一了这些框架，提供了一套有利于图网络设计的图数据模型、图操作算子等。

- 信息传递框架（MPNNs）
信息传递框架模型提供了一套整图结构中数据如何流转、如何相互影响的框架。主要分为两个阶段，信息传播阶段和信息输出阶段。信息传播阶段主要负责构建信息如何在节点、边、全局之间相互传播和更新演化，主要包括信息传播函数、更新函数。信息输出阶段主要负责构建隐空间向量到具体标签或数值的转换，主要包括读出转换函数。不同的需求需要设置不同的三个函数，由此产生了不同的模型变种。

- 捕获长程依赖模型（NLNN）
捕获长程依赖模型（NLNN）主要提出了一种通过非局部操作来捕获长程依赖性的操作技巧，可以被看成是一种自注意力机制类似的方法。一般的操作有Gaussian、Embedded Gaussian、Dot product、Concatenation等。这些操作方法都不会影响和改变MPNN所提出的框架，而只是框架下面一些值得考虑和尝试的设计操作的技巧。

- 通用图建模框架（GN）
通用图建模框架（GN）是一种通用的图网络框架，可以扩展各种图神经网络，包括上述两种MPNNs和NLNN。该框架提供了一套新的图数据模型、图网络操作算子，可以通过传播、更新等方法来表示图属性、节点属性以及边属性之间的相互影响。该框架最好的地方在于，提供一套可以组合的算子模块，网络设计者可以通过具体的需求实现不同的网络结构（函数表达式）。

## 3 复杂系统抽象

图神经网络已经从最初的图谱卷积和中心节点方法中走出来，逐步从系统的角度去考虑如何设计，这个更像是一个推理模型的初始阶段。这也是为什么有人认为深度学习终结，图神经网络才是拐点。站在系统的角度，万物都是有联系的，这些联系有些是明显的，有些则不是明显的，但这些都构成了一个巨大的拓扑图。那么是否存在一种方式去学习一个系统中，两个物体具有怎么样的相互作用呢？这个问题的研究当然首先会想到信息的传播，因为一个物体对另一个物体的相互作用总是需要一定的介质，可以是太阳光传播到我这，我闭了一下眼睛，也可以是我加你QQ好友，你通过，我们成为新朋友，这些连接以及这些连接所产生的作用，都是通过信息的传播完成。把这些信息传播的流程抽象成我们上述的三种类型的函数，便可完成系统中两个物体相互作用的模拟，而NLNN框架则更像是提出了一些常见的两个物体相互作用的方式。如果把一个系统在某个时刻的状态构建成一个图，那么，通过足够时长的数据收集，就能获得一个系统的一系列状态图（时序状态图），简称为时序图。如果我们能构建一个深度学习网络来学习这些时序图的规律，用历史的图数据来预测未来的图数据，那么我们就能实现对一个系统的预测，预测下一状态，系统中各个个体的状态是什么样的，各个个体之间的关系是怎么样的，整个系统的状态又是怎么样的等。系统中这些链接数据收集得越多，我们越能学习到个体与系统之间、个体之间相互影响的规律，从而进一步获得整个系统运作的规律。具体抽象到图数据模型就是节点分类预测、链接预测、边属性预测、图属性预测等问题。比如ST—GCN模型，就把人体的骨骼节点构成一系列的时序图网络，来学习各骨骼节点相互作用的模式，由此学习人体的姿态估计。<br>

<div align=center><img src="https://github.com/xchadesi/st_graph_book/blob/master/docs/images/71.PNG"/></div>

当图神经网络能够实现以上的预测功能后，基本上就完成了一定的推理功能。这种推理和传统的规则引擎推理以及基于知识库的推理不同，这里并不需要去建立一套复杂的本体对象，也不要对其进行规则化描述，而只需要构建时序图网络，而时序图网络的构建相对于复杂的知识库来说简单很多。这里再具体解释一下推理，比如系统中，A物体在B物体的右边，C物体在A物体的右边，那么学习到C是在B物体的右边就是简单的推理：右边的右边，还是右边。关于推理，一直是专家系统、知识图谱等研究的重点方向，但一直没有太大的突破，但图神经网络的出现，给该问题带来了一些曙光。但存在的问题是，这种时序图数据的积累目前还是有限的，对于监督学习来说，还是一个比较大的问题。<br>

上述提到了一个关键的模型---时序图。作为图神经网络应用的对象，时序图数据模型的构建显得尤为重要。时序图数据模型是时序模型和图结构模型的融合，该种数据模型是对一个复杂系统的抽象。在第六章，我们提到一个时序以及时序图网络模型的一个应用场景是物联网。物联网中存在几大数据模型，包括物模型、事件模型、感知数据模型等，物模型是语义图谱，事件和感知数据都是序列模型，而不同感知节点之间的关系又构成了图模型，所以物联网产生的数据其实天然就是一些时序图模型。比如我们常见的交通预测问题，利用传感器记录车流、速度、距离等数据，来预测某个站点的车流情况。随着物联网的爆发，时序图网络以及图神经网络可能都会迎来它们的“春天”。<br>
<div align=center><img src="https://github.com/xchadesi/st_graph_book/blob/master/docs/images/72.PNG"/></div>

## 4 基本模型

基本的图卷积网络算子可以表示为如下的式子,设中心节点为i：<br>
<div align=center><img src="https://github.com/xchadesi/st_graph_book/blob/master/docs/images/73.PNG"/></div>

其中：<br>

<div align=center><img src="https://github.com/xchadesi/st_graph_book/blob/master/docs/images/74.PNG"/></div>

首先，对于每个节点i，获取其直接邻节点域Ni（一般是固定数目，如果每个中心节点的数目不同，则无法共享参数）,在邻节点域内，中心节点根据所有邻节点传播过来的特征，对自身的特征h进行更新，随着层次l的增加，中心节点特征也是可以被非直接相邻的节点特征所影响。迭代层次结束后，我们就可以获得每个节点的特征表达，在特征向量表示的基础上，可以给其添加一个映射函数R（h）,使其获得到端的训练效果。

综上，图卷积神经网络具有卷积神经网络的一些性质，比如：
- 局部参数共享，算子是适用于每个节点（圆圈代表算子），处处共享。
- 感受域正比于层数，最开始的时候，每个节点包含了直接邻居的信息，再计算第二层时就能把邻居的邻居的信息包含进来，这样参与运算的信息就更多更充分。层数越多，感受域就更广，参与运算的信息就更多。

## 5 The Tools of the GraphNeuralNetwork

名称  | 类型  | 适用场景 | Github
 ---- | ----- | ------  | ------ 
 OpenNE	| 图表示学习	| 图节点表示学习，预训练 |	https://github.com/thunlp/OpenNE
Graph_nets |	图神经网络	| 基于关系模糊的图数据推理	| https://github.com/deepmind/graph_nets
DGL	| 图神经网络 |	建立图数据（可以无需通过networkx）并加载常用图神经网络 |	https://github.com/jermainewang/dgl
GPF	| 训练流程	| 基于关系数据的数据预测（节点分类、关系预测）|	https://github.com/xchadesi/GPF
networkx	| 图数据预处理	| 非大规模图数据预处理	| https://github.com/networkx/networkx
Euler	|工业级图深度学习框架	| 工业级图数据的用户研究快速进行算法创新与定制 |	https://github.com/alibaba/euler
